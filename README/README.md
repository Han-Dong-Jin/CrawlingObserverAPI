# CrawlingObserver

CrawlingObserver는 다양한 데이터를 크롤링하고 저장 및 관리하는 Python 기반 프로젝트입니다. 이 프로젝트는 설정 파일을 통해 유연하게 동작을 제어할 수 있으며, 데이터베이스와 파일 저장 방식을 지원합니다.

---

## 주요 기능

- **데이터 크롤링**: 뉴스, 리포트, 금융 데이터, 주식 데이터를 크롤링.
- **설정 파일 관리**: `settings.yaml`을 통해 크롤링 동작 및 저장 방식을 설정.
- **데이터 저장**: 데이터베이스 또는 파일로 저장 가능.
- **유연한 로깅**: 컬러 로그 및 에러 로그 출력 설정 지원.
- **테스트 모드**: 테스트 환경에서 동작을 제어할 수 있는 옵션 제공.

---

## 프로젝트 구조

```
CrawlingObserver/
├── lib/
│   ├── Crawling/               # 크롤링 관련 코드
│   ├── Config/                 # 설정 파일 관리 코드
│   └── Distributor/            # 데이터 분배 관련 코드
├── settings.yaml               # 프로젝트 설정 파일
├── main.py                     # 프로젝트 진입점
└── README.md                   # 프로젝트 설명 파일
```

---

## 설정 파일 (`settings.yaml`)

`settings.yaml` 파일은 프로젝트의 동작을 제어하는 설정 파일입니다. 주요 항목은 다음과 같습니다:

- **API_KEYS**: API 키 설정.
- **크롤링 관련 설정**: 크롤링 데이터 크기 및 재시도 횟수 설정.
- **저장 방식**: 데이터베이스 또는 파일 저장 방식 선택.
- **데이터베이스 설정**: 데이터베이스 연결 URL.
- **로깅 설정**: 컬러 로그 및 에러 로그 출력 여부.
- **테스트 모드**: 테스트 환경에서의 동작 제어.
- **크롤러 스위치**: 크롤러 활성화 여부 설정.

---

## 설치 및 실행

### 1. 의존성 설치

프로젝트 실행에 필요한 패키지를 설치합니다:

```bash
pip install -r requirements.txt
```

### 2. 설정 파일 수정

`settings.yaml` 파일을 열어 프로젝트에 맞는 설정을 입력합니다.

### 3. 실행

프로젝트를 실행하려면 다음 명령어를 사용합니다:

```bash
python main.py
```

---

## 기여 방법

1. 이 저장소를 포크합니다.
2. 새로운 브랜치를 생성합니다: `git checkout -b feature/새로운기능`.
3. 변경 사항을 커밋합니다: `git commit -m "Add 새로운 기능"`.
4. 브랜치에 푸시합니다: `git push origin feature/새로운기능`.
5. Pull Request를 생성합니다.

---

## 라이선스

이 프로젝트는 MIT 라이선스를 따릅니다. 자세한 내용은 `LICENSE` 파일을 참조하세요.
